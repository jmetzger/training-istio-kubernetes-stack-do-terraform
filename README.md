# DigitalOcean Kubernetes Setup mit Terraform & Calico Operator

Dieses Repository automatisiert den Aufbau eines selbstverwalteten Kubernetes-Clusters auf DigitalOcean mit:

- Terraform-Infrastruktur (VPC, Droplets, SSH Key, Helm, DNS)
- Kubernetes-Installation via Cloud-init + kubeadm
- Calico CNI via Tigera Operator
- MetalLB LoadBalancer mit L2 Propagation
- Traefik Ingress Controller
- Automatischer `kubeadm join` per SSH + kubeconfig Ãœbergabe

---

## ğŸ§° Voraussetzungen

- DigitalOcean-Account + API Token (Ã¼ber Umgebungsvariable setzen mit `export TF_VAR_do_token="<your_token>"`)
- Domain wie `do.t3isp.de` in DigitalOcean DNS verwaltet
- `terraform`, `jq`, `ssh`, `scp` lokal installiert
- `helmfile` (optional, fÃ¼r cert-manager Deployment)
- SSH-Zugriff auf erzeugte Droplets (automatisch eingerichtet)

---

## ğŸš€ Schnellstart

> Alternativ kannst du dein API-Token auch in einer `.env`-Datei speichern und mit `source .env` laden:
>
> ```env
> export TF_VAR_do_token="<your_token>"
> ```

```bash
# DigitalOcean API Token als Umgebungsvariable setzen
export TF_VAR_do_token="<your_token>"
# Terraform initialisieren und Infrastruktur provisionieren
terraform init
terraform apply -auto-approve
```

Nach erfolgreicher Initialisierung wird die Kubernetes-Konfiguration (`admin.conf`) automatisch vom Control-Plane-Node kopiert und gespeichert als:

```bash
~/.kube/config
```

Falls das Verzeichnis `~/.kube` noch nicht existiert, wird es automatisch erstellt.

---

## ğŸ“ Struktur

```
â”œâ”€â”€ main.tf                 # Hauptlogik
â”œâ”€â”€ variables.tf            # Eingabeparameter
â”œâ”€â”€ outputs.tf              # Ausgaben
â”œâ”€â”€ cloud-init/
â”‚   â””â”€â”€ setup-k8s-node.sh   # Cloud-init fÃ¼r Droplets
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ join-workers.sh     # Initialisiert Cluster, joined Worker & kopiert kubeconfig
â””â”€â”€ README.md
```

---

## âš™ï¸ Komponenten & Versionen

- Terraform: >= 1.4.0
- Kubernetes: `1.33.0-00` (Fallback: `1.32.3-00`)
- Calico: Tigera Operator (CRD-basiert)
- MetalLB: Helm Chart `0.13.12`
- Traefik: Helm Chart `38.0.2` (ohne CRDs)

---

## ğŸ“¡ DNS Setup

Nach der Ingress-Installation werden automatisch A-Records erstellt:

> Hinweis: Der zweite Eintrag verwendet dynamisch den aktuell eingeloggten Benutzer (z.â€¯B. `tln1`) durch Auslesen von `$USER` oder `$USERNAME`.

- `*.tln1.do.t3isp.de â†’ LoadBalancer IP` (wird automatisch anhand des angemeldeten Benutzers generiert)

---

## ğŸ§ª Validierung

```bash
kubectl get nodes
kubectl get pods -A
kubectl get ipaddresspool -n metallb-system

# Traefik Ingress Controller prÃ¼fen
kubectl -n ingress get pods
kubectl -n ingress get svc
```

---

## ğŸ“¦ Helmfile Deployment (cert-manager)

Nach dem erfolgreichen Terraform-Setup kann zusÃ¤tzlich cert-manager Ã¼ber helmfile installiert werden.

### Was macht helmfile sync?

`helmfile sync` deployed alle in der `helmfile.yaml` definierten Helm Releases:
- **cert-manager** (Jetstack): Automatisiertes TLS-Zertifikatmanagement
- **cert-manager-config**: ClusterIssuer fÃ¼r Let's Encrypt (HTTP-01 Challenge)

### Wann sollte helmfile sync verwendet werden?

- **Initial**: Nach `terraform apply`, sobald der Cluster lÃ¤uft
- **Updates**: Nach Ã„nderungen an `helmfile.yaml` oder `charts/`
- **Reparatur**: Wenn cert-manager-Ressourcen fehlen oder inkonsistent sind

### Anwendung

```bash
# Voraussetzung: helmfile installiert (https://helmfile.readthedocs.io/)
# Deploye alle Releases
helmfile sync

# Nur bestimmtes Release deployen
helmfile -l name=cert-manager sync

# Dry-run (zeigt was passieren wÃ¼rde)
helmfile diff
```

### Was wird deployed?

```bash
# Nach helmfile sync prÃ¼fen
kubectl get pods -n cert-manager
kubectl get clusterissuer

# Erwartete Ausgabe:
# - cert-manager, cert-manager-webhook, cert-manager-cainjector Pods
# - ClusterIssuer: letsencrypt-prod
```

---

## ğŸ’¾ NFS CSI Driver (Persistenter Storage)

Der NFS CSI Driver wird separat via `helmfile-csi-nfs.yaml` installiert und setzt `nfs-csi` als Default-StorageClass.

### Voraussetzungen

- NFS Server erreichbar unter Private IP `10.135.0.7`
- NFS Share: `/var/nfs`

### Installation

```bash
helmfile -f helmfile-csi-nfs.yaml sync
```

### Validierung

```bash
# CSI Driver Pods prÃ¼fen
kubectl get pods -n kube-system | grep csi-nfs

# StorageClass prÃ¼fen (nfs-csi sollte als default markiert sein)
kubectl get storageclass
```

Erwartete Ausgabe:
```
NAME                PROVISIONER      RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION
nfs-csi (default)   nfs.csi.k8s.io   Retain          Immediate           false
```

### Struktur

```
â”œâ”€â”€ helmfile-csi-nfs.yaml           # Helmfile fÃ¼r CSI Driver + StorageClass
â””â”€â”€ charts/
    â””â”€â”€ nfs-csi-storageclass/       # Custom Chart fÃ¼r StorageClass
        â”œâ”€â”€ Chart.yaml
        â”œâ”€â”€ values.yaml             # NFS Server IP und Share konfigurierbar
        â””â”€â”€ templates/
            â””â”€â”€ storageclass.yaml
```

---

## â— Sicherheitshinweis

Der generierte private SSH-Key `id_rsa_k8s_do` wird lokal gespeichert. Bitte sicher verwahren und nicht ins Git einchecken:

```bash
.gitignore:
  id_rsa_k8s_do
  .terraform/
  terraform.tfstate*
```

---

## ğŸ§¼ Bereinigen

### Empfohlene Methode: Safe Destroy Script

```bash
# Verwendet automatisches State-Cleanup bei Provider-Timeout
./scripts/safe-destroy.sh
rm -f id_rsa_k8s_do id_rsa_k8s_do.pub
```

**Was macht `safe-destroy.sh`?**

1. FÃ¼hrt `terraform destroy` aus (ignoriert Timeout-Fehler)
2. Verifiziert dass alle k8s-Droplets in DigitalOcean gelÃ¶scht wurden
3. RÃ¤umt automatisch den Terraform State auf wenn Droplets weg sind

**Warum ist das nÃ¶tig?**

Der DigitalOcean Provider v2.74.0 hat einen hardcodierten 1-Minuten-Timeout beim Warten auf den "archive"-Status. Droplets werden trotz Timeout-Fehler korrekt gelÃ¶scht, aber der Terraform State bleibt inkonsistent. Das Script verifiziert die tatsÃ¤chliche LÃ¶schung und rÃ¤umt den State sauber auf.

### Alternative: Standard Destroy

```bash
terraform destroy -auto-approve
# Bei Timeout-Fehlern: Manuelles State-Cleanup erforderlich
rm -f id_rsa_k8s_do id_rsa_k8s_do.pub
```

